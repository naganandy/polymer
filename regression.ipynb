{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read polymer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polymer\n",
    "data =  polymer.read(\"polymer.csv\", normalise = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split to train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.8   # percentage for training\n",
    "splits, s = [], 100  # get s splits\n",
    "\n",
    "for i in range(s):\n",
    "    train, test = data.split(p, i)\n",
    "    splits.append((train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vanilla linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1323.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  2.395 +- 1.758\n",
      "r2:  0.354 +- 1.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "mse, r2 = [], []\n",
    "for i in tqdm(range(s)):\n",
    "    train, test = splits[i]\n",
    "    \n",
    "    reg = linear_model.LinearRegression()\n",
    "    _ = reg.fit(train[\"X\"], train[\"Y\"])\n",
    "    Z = reg.predict(test[\"X\"])\n",
    "\n",
    "    mse.append(mean_squared_error(test[\"Y\"], Z))\n",
    "    r2.append(r2_score(test[\"Y\"], Z))\n",
    "    \n",
    "print(\"mse: \", round(np.mean(mse), 3), \"+-\", round(np.std(mse), 3))\n",
    "print(\"r2: \", round(np.mean(r2), 3), \"+-\", round(np.std(r2), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  2.46 +- 1.781\n",
      "r2:  0.279 +- 1.19\n"
     ]
    }
   ],
   "source": [
    "mse, r2 = [], []\n",
    "for i in tqdm(range(s)):\n",
    "    train, test = splits[i]\n",
    "    \n",
    "    reg = linear_model.LassoCV(cv=5, random_state=0)\n",
    "    _ = reg.fit(train[\"X\"], train[\"Y\"])\n",
    "    Z = reg.predict(test[\"X\"])\n",
    "\n",
    "    mse.append(mean_squared_error(test[\"Y\"], Z))\n",
    "    r2.append(r2_score(test[\"Y\"], Z))\n",
    "    \n",
    "print(\"mse: \", round(np.mean(mse), 3), \"+-\", round(np.std(mse), 3))\n",
    "print(\"r2: \", round(np.mean(r2), 3), \"+-\", round(np.std(r2), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 672.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  2.407 +- 1.736\n",
      "r2:  0.333 +- 1.117\n"
     ]
    }
   ],
   "source": [
    "mse, r2 = [], []\n",
    "for i in tqdm(range(s)):\n",
    "    train, test = splits[i]\n",
    "    \n",
    "    reg = linear_model.RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10, 100, 1000])\n",
    "    _ = reg.fit(train[\"X\"], train[\"Y\"])\n",
    "    Z = reg.predict(test[\"X\"])\n",
    "\n",
    "    mse.append(mean_squared_error(test[\"Y\"], Z))\n",
    "    r2.append(r2_score(test[\"Y\"], Z))\n",
    "    \n",
    "print(\"mse: \", round(np.mean(mse), 3), \"+-\", round(np.std(mse), 3))\n",
    "print(\"r2: \", round(np.mean(r2), 3), \"+-\", round(np.std(r2), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1431.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  1.281 +- 1.204\n",
      "r2:  0.796 +- 0.335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "mse, r2 = [], []\n",
    "for i in tqdm(range(s)):\n",
    "    train, test = splits[i]\n",
    "    \n",
    "    reg = DecisionTreeRegressor()\n",
    "    _ = reg.fit(train[\"X\"], train[\"Y\"])\n",
    "    Z = reg.predict(test[\"X\"])\n",
    "\n",
    "    mse.append(mean_squared_error(test[\"Y\"], Z))\n",
    "    r2.append(r2_score(test[\"Y\"], Z))\n",
    "    \n",
    "print(\"mse: \", round(np.mean(mse), 3), \"+-\", round(np.std(mse), 3))\n",
    "print(\"r2: \", round(np.mean(r2), 3), \"+-\", round(np.std(r2), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1089.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  1.303 +- 1.027\n",
      "r2:  0.832 +- 0.202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "mse, r2 = [], []\n",
    "for i in tqdm(range(s)):\n",
    "    train, test = splits[i]\n",
    "    \n",
    "    reg = SVR(gamma=0.1, C=10, epsilon=0.3)\n",
    "    _ = reg.fit(train[\"X\"], train[\"Y\"])\n",
    "    Z = reg.predict(test[\"X\"])\n",
    "\n",
    "    mse.append(mean_squared_error(test[\"Y\"], Z))\n",
    "    r2.append(r2_score(test[\"Y\"], Z))\n",
    "    \n",
    "print(\"mse: \", round(np.mean(mse), 3), \"+-\", round(np.std(mse), 3))\n",
    "print(\"r2: \", round(np.mean(r2), 3), \"+-\", round(np.std(r2), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [run all cells](https://stackoverflow.com/questions/33143753/jupyter-ipython-notebooks-shortcut-for-run-all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "Jupyter.keyboard_manager.command_shortcuts.add_shortcut('r', {\n",
       "    help : 'run all cells',\n",
       "    help_index : 'zz',\n",
       "    handler : function (event) {\n",
       "        IPython.notebook.execute_all_cells();\n",
       "        return false;\n",
       "    }}\n",
       ");"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "Jupyter.keyboard_manager.command_shortcuts.add_shortcut('r', {\n",
    "    help : 'run all cells',\n",
    "    help_index : 'zz',\n",
    "    handler : function (event) {\n",
    "        IPython.notebook.execute_all_cells();\n",
    "        return false;\n",
    "    }}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import sklearn, math, itertools, optunity, optunity.metrics\\n\\n# we explicitly generate the outer_cv decorator so we can use it twice\\ntrain, test = splits[0]\\ndata, targets = train[\"X\"], train[\"Y\"]\\nouter_cv = optunity.cross_validated(x=data, y=targets, num_folds=3)\\n\\nspace = {\\'kernel\\': {\\'linear\\': {\\'C\\': [0, 100]},\\n                    \\'rbf\\': {\\'gamma\\': [0, 50], \\'C\\': [1, 100]},\\n                    \\'poly\\': {\\'degree\\': [2, 5], \\'C\\': [1000, 20000], \\'coef0\\': [0, 1]}\\n                    }\\n         }\\n\\ndef compute_mse_all_tuned(x_train, y_train, x_test, y_test):\\n    \"\"\"Computes MSE of an SVR with RBF kernel and optimized hyperparameters.\"\"\"\\n\\n    # define objective function for tuning\\n    @optunity.cross_validated(x=x_train, y=y_train, num_iter=2, num_folds=5)\\n    def tune_cv(x_train, y_train, x_test, y_test, kernel, C, gamma, degree, coef0):\\n        if kernel == \\'linear\\':\\n            model = sklearn.svm.SVR(kernel=kernel, C=C)\\n        elif kernel == \\'poly\\':\\n            model = sklearn.svm.SVR(kernel=kernel, C=C, degree=degree, coef0=coef0)\\n        elif kernel == \\'rbf\\':\\n            model = sklearn.svm.SVR(kernel=kernel, C=C, gamma=gamma)\\n        else:\\n            raise ArgumentError(\"Unknown kernel function: %s\" % kernel)\\n        model.fit(x_train, y_train)\\n\\n        predictions = model.predict(x_test)\\n        return optunity.metrics.mse(y_test, predictions)\\n\\n    # optimize parameters\\n    optimal_pars, _, _ = optunity.minimize_structured(tune_cv, num_evals=150, search_space=space)\\n\\n    # remove hyperparameters with None value from optimal pars\\n    for k, v in optimal_pars.items():\\n        if v is None: del optimal_pars[k]\\n    print(\"optimal hyperparameters: \" + str(optimal_pars))\\n\\n    tuned_model = sklearn.svm.SVR(**optimal_pars).fit(x_train, y_train)\\n    predictions = tuned_model.predict(x_test)\\n    return optunity.metrics.mse(y_test, predictions)\\n\\n# wrap with outer cross-validation\\ncompute_mse_all_tuned = outer_cv(compute_mse_all_tuned)\\n\\ncompute_mse_all_tuned()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import sklearn, math, itertools, optunity, optunity.metrics\n",
    "\n",
    "# we explicitly generate the outer_cv decorator so we can use it twice\n",
    "train, test = splits[0]\n",
    "data, targets = train[\"X\"], train[\"Y\"]\n",
    "outer_cv = optunity.cross_validated(x=data, y=targets, num_folds=3)\n",
    "\n",
    "space = {'kernel': {'linear': {'C': [0, 100]},\n",
    "                    'rbf': {'gamma': [0, 50], 'C': [1, 100]},\n",
    "                    'poly': {'degree': [2, 5], 'C': [1000, 20000], 'coef0': [0, 1]}\n",
    "                    }\n",
    "         }\n",
    "\n",
    "def compute_mse_all_tuned(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Computes MSE of an SVR with RBF kernel and optimized hyperparameters.\"\"\"\n",
    "\n",
    "    # define objective function for tuning\n",
    "    @optunity.cross_validated(x=x_train, y=y_train, num_iter=2, num_folds=5)\n",
    "    def tune_cv(x_train, y_train, x_test, y_test, kernel, C, gamma, degree, coef0):\n",
    "        if kernel == 'linear':\n",
    "            model = sklearn.svm.SVR(kernel=kernel, C=C)\n",
    "        elif kernel == 'poly':\n",
    "            model = sklearn.svm.SVR(kernel=kernel, C=C, degree=degree, coef0=coef0)\n",
    "        elif kernel == 'rbf':\n",
    "            model = sklearn.svm.SVR(kernel=kernel, C=C, gamma=gamma)\n",
    "        else:\n",
    "            raise ArgumentError(\"Unknown kernel function: %s\" % kernel)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        predictions = model.predict(x_test)\n",
    "        return optunity.metrics.mse(y_test, predictions)\n",
    "\n",
    "    # optimize parameters\n",
    "    optimal_pars, _, _ = optunity.minimize_structured(tune_cv, num_evals=150, search_space=space)\n",
    "\n",
    "    # remove hyperparameters with None value from optimal pars\n",
    "    for k, v in optimal_pars.items():\n",
    "        if v is None: del optimal_pars[k]\n",
    "    print(\"optimal hyperparameters: \" + str(optimal_pars))\n",
    "\n",
    "    tuned_model = sklearn.svm.SVR(**optimal_pars).fit(x_train, y_train)\n",
    "    predictions = tuned_model.predict(x_test)\n",
    "    return optunity.metrics.mse(y_test, predictions)\n",
    "\n",
    "# wrap with outer cross-validation\n",
    "compute_mse_all_tuned = outer_cv(compute_mse_all_tuned)\n",
    "\n",
    "compute_mse_all_tuned()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
